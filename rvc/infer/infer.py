import asyncio
import gc
import os

import edge_tts
import gradio as gr
import torch
from fairseq.checkpoint_utils import load_model_ensemble_and_task
from fairseq.data.dictionary import Dictionary
from pydub import AudioSegment
from scipy.io import wavfile

from rvc.infer.config import Config
from rvc.infer.pipeline import VC
from rvc.lib.algorithm.synthesizers import Synthesizer
from rvc.lib.my_utils import load_audio

# –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—É—Ç–∏ –∫ –ø–∞–ø–∫–∞–º –∏ —Ñ–∞–π–ª–∞–º (–∫–æ–Ω—Å—Ç–∞–Ω—Ç—ã)
RVC_MODELS_DIR = os.path.join(os.getcwd(), "models", "RVC_models")
OUTPUT_DIR = os.path.join(os.getcwd(), "output", "RVC_output")
HUBERT_BASE_PATH = os.path.join(os.getcwd(), "rvc", "models", "embedders", "hubert_base.pt")

# –°–æ–∑–¥–∞–µ–º –ø–∞–ø–∫–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ—Ç
os.makedirs(RVC_MODELS_DIR, exist_ok=True)
os.makedirs(OUTPUT_DIR, exist_ok=True)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
config = Config()


# –û—Ç–æ–±—Ä–∞–∂–∞–µ—Ç –ø—Ä–æ–≥—Ä–µ—Å—Å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –∑–∞–¥–∞—á–∏.
def display_progress(percent, message, progress=gr.Progress()):
    print(message)
    progress(percent, desc=message)


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å –ø–æ –∏–º–µ–Ω–∏ –º–æ–¥–µ–ª–∏.
def load_rvc_model(rvc_model):
    # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—É—Ç—å –∫ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_dir = os.path.join(RVC_MODELS_DIR, rvc_model)
    # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ —Ñ–∞–π–ª–æ–≤ –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
    model_files = os.listdir(model_dir)

    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .pth
    rvc_model_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".pth")), None)
    # –ù–∞—Ö–æ–¥–∏–º —Ñ–∞–π–ª –∏–Ω–¥–µ–∫—Å–∞ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ–º .index
    rvc_index_path = next((os.path.join(model_dir, f) for f in model_files if f.endswith(".index")), None)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏
    if not rvc_model_path:
        raise ValueError(
            f"\033[91m–û–®–ò–ë–ö–ê!\033[0m –ú–æ–¥–µ–ª—å {rvc_model} –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∞. –í–æ–∑–º–æ–∂–Ω–æ, –≤—ã –¥–æ–ø—É—Å—Ç–∏–ª–∏ –æ—à–∏–±–∫—É –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏ –∏–ª–∏ —É–∫–∞–∑–∞–ª–∏ –Ω–µ–≤–µ—Ä–Ω—É—é —Å—Å—ã–ª–∫—É –ø—Ä–∏ —É—Å—Ç–∞–Ω–æ–≤–∫–µ."
        )

    return rvc_model_path, rvc_index_path


# –ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å Hubert
def load_hubert(model_path):
    torch.serialization.add_safe_globals([Dictionary])
    model, _, _ = load_model_ensemble_and_task([model_path], suffix="")
    hubert = model[0].to(config.device).float()
    hubert.eval()
    return hubert


# –ü–æ–ª—É—á–∞–µ—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
def get_vc(model_path):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–æ–¥–µ–ª–∏ –∏–∑ —Ñ–∞–π–ª–∞
    cpt = torch.load(model_path, map_location="cpu", weights_only=True)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ñ–æ—Ä–º–∞—Ç–∞ –º–æ–¥–µ–ª–∏
    if "config" not in cpt or "weight" not in cpt:
        raise ValueError(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–ª—è {model_path}. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –≥–æ–ª–æ—Å–æ–≤—É—é –º–æ–¥–µ–ª—å, –æ–±—É—á–µ–Ω–Ω—É—é –Ω–∞ RVC v2.")

    # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏
    tgt_sr = cpt["config"][-1]
    cpt["config"][-3] = cpt["weight"]["emb_g.weight"].shape[0]
    pitch_guidance = cpt.get("f0", 1)
    version = cpt.get("version", "v1")
    # vocoder = cpt.get("vocoder", "HiFi-GAN") ‚Äî –Ω–∞ –±—É–¥—É—â–µ–µ
    input_dim = 768 if version == "v2" else 256

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–Ω—Ç–µ–∑–∞—Ç–æ—Ä
    net_g = Synthesizer(*cpt["config"], use_f0=pitch_guidance, input_dim=input_dim)

    # –£–¥–∞–ª—è–µ–º –Ω–µ–Ω—É–∂–Ω—ã–π —Å–ª–æ–π
    del net_g.enc_q
    net_g.load_state_dict(cpt["weight"], strict=False)
    net_g = net_g.to(config.device).float()
    net_g.eval()

    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ–±—ä–µ–∫—Ç –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä–∞ –≥–æ–ª–æ—Å–∞
    vc = VC(tgt_sr, config)
    return cpt, version, net_g, tgt_sr, vc


# –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ —Å—Ç–µ—Ä–µ–æ –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–∞—Ç
def convert_audio(input_audio, output_audio, output_format):
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    audio = AudioSegment.from_file(input_audio)

    # –ï—Å–ª–∏ –∞—É–¥–∏–æ –º–æ–Ω–æ, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –µ–≥–æ –≤ —Å—Ç–µ—Ä–µ–æ
    if audio.channels == 1:
        audio = audio.set_channels(2)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª –≤ –≤—ã–±—Ä–∞–Ω–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
    audio.export(output_audio, format=output_format)


# –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç –≤ —Ä–µ—á—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º edge_tts.
async def text_to_speech(voice, text, rate, volume, pitch, output_path):
    if not (-100 <= rate <= 100):
        raise ValueError(f"Rate –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100% –¥–æ +100%")
    if not (-100 <= volume <= 100):
        raise ValueError(f"Volume –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100% –¥–æ +100%")
    if not (-100 <= pitch <= 100):
        raise ValueError(f"Pitch –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ –æ—Ç -100Hz –¥–æ +100Hz")

    rate = f"+{rate}%" if rate >= 0 else f"{rate}%"
    volume = f"+{volume}%" if volume >= 0 else f"{volume}%"
    pitch = f"+{pitch}Hz" if pitch >= 0 else f"{pitch}Hz"

    communicate = edge_tts.Communicate(voice=voice, text=text, rate=rate, volume=volume, pitch=pitch)
    await communicate.save(output_path)


# –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º RVC
def rvc_infer(
    # RVC
    rvc_model=None,
    input_path=None,
    f0_method="rmvpe",
    f0_min=50,
    f0_max=1100,
    hop_length=128,
    rvc_pitch=0,
    protect=0.5,
    index_rate=0,
    volume_envelope=1,
    output_format="wav",
    # EdgeTTS
    use_tts=False,
    tts_voice=None,
    tts_text=None,
    tts_rate=0,
    tts_volume=0,
    tts_pitch=0,
):
    if not rvc_model:
        raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å –≥–æ–ª–æ—Å–∞ –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è.")

    display_progress(0, "\n[‚öôÔ∏è] –ó–∞–ø—É—Å–∫ –∫–æ–Ω–≤–µ–π–µ—Ä–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏...")
    if use_tts:
        if not tts_text:
            raise ValueError("–í–≤–µ–¥–∏—Ç–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–π —Ç–µ–∫—Å—Ç –≤ –ø–æ–ª–µ –¥–ª—è –≤–≤–æ–¥–∞.")
        if not tts_voice:
            raise ValueError("–í—ã–±–µ—Ä–∏—Ç–µ —è–∑—ã–∫ –∏ –≥–æ–ª–æ—Å –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏.")

        display_progress(0.2, "[üéôÔ∏è] –°–∏–Ω—Ç–µ–∑ —Ä–µ—á–∏...")
        input_path = os.path.join(OUTPUT_DIR, "TTS_Voice.wav")
        asyncio.run(text_to_speech(tts_voice, tts_text, tts_rate, tts_volume, tts_pitch, input_path))
    else:
        if not os.path.exists(input_path):
            raise ValueError(
                f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ –∞—É–¥–∏–æ—Ñ–∞–π–ª {input_path}. –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª –∑–∞–≥—Ä—É–∑–∏–ª—Å—è –∏–ª–∏ –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –ø—É—Ç–∏ –∫ –Ω–µ–º—É."
            )

    base_name = os.path.splitext(os.path.basename(input_path))[0]
    output_path = os.path.join(OUTPUT_DIR, f"{base_name}_(Converted).{output_format}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å Hubert
    hubert_model = load_hubert(HUBERT_BASE_PATH)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å RVC –∏ –∏–Ω–¥–µ–∫—Å
    model_path, index_path = load_rvc_model(rvc_model)
    # –ü–æ–ª—É—á–∞–µ–º –∫–æ–Ω–≤–µ—Ä—Ç–µ—Ä –≥–æ–ª–æ—Å–∞
    cpt, version, net_g, tgt_sr, vc = get_vc(model_path)
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—É–¥–∏–æ—Ñ–∞–π–ª
    audio = load_audio(input_path, 16000)
    pitch_guidance = cpt.get("f0", 1)

    display_progress(0.5, f"[üåå] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∞—É–¥–∏–æ ‚Äî {base_name}...")
    audio_opt = vc.pipeline(
        hubert_model,
        net_g,
        0,
        audio,
        rvc_pitch,
        f0_method,
        index_path,
        index_rate,
        pitch_guidance,
        volume_envelope,
        version,
        protect,
        hop_length,
        f0_file=None,
        f0_min=f0_min,
        f0_max=f0_max,
    )
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ wav —Ñ–∞–π–ª
    wavfile.write(output_path, tgt_sr, audio_opt)

    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Ñ–∞–π–ª –≤ —Å—Ç–µ—Ä–µ–æ –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–π –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º —Ñ–æ—Ä–º–∞—Ç
    display_progress(0.8, "[üí´] –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∞—É–¥–∏–æ –≤ —Å—Ç–µ—Ä–µ–æ...")
    convert_audio(output_path, output_path, output_format)

    display_progress(1.0, f"[‚úÖ] –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ ‚Äî {output_path}")

    # –û—Å–≤–æ–±–æ–∂–¥–∞–µ–º –ø–∞–º—è—Ç—å
    del hubert_model, cpt, net_g, vc
    gc.collect()
    torch.cuda.empty_cache()

    if use_tts:
        return output_path, input_path
    return output_path
